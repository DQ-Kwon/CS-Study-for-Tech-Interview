원글 : https://foil-radius-405.notion.site/OS-Question-b047880f335940ffa59232cff51740d0

---

# 📔 Process & Thread

<aside>
❓ 프로세스와 스레드의 차이를 설명하세요.

</aside>

`프로세스` : 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램

`스레드` : 프로세스 내에서 실행되는 여러 흐름의 단위

<aside>
❓ 멀티 프로세스와 멀티 스레드의 차이를 설명하세요.

</aside>

`멀티 프로세스` : 하나의 응용프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업(태스크)을 처리하도록 하는 것

`멀티 스레드` : 하나의 응용프로그램을 여러 개의 스레드로 구성하고 각 스레드로 하여금 하나의 작업을 처리하도록 하는 것

# 📔 System call

<aside>
❓ 시스템 콜에 대해 설명해주세요.

</aside>

커널 영역의 기능을 사용자 모드가 사용 가능하게, 즉 프로세스가 하드웨어에 직접 접근해서 필요한 기능을 사용할 수 있도록 해주는 호출

- 유저 영역 : 프로그램이 동작하기 위해 사용되는 메모리 공간(코드 영역, 데이터 영역, 스택 및 힙 영역)
- 커널 영역 : 운영체제라는 하나의 소프트웨어를 실행시키기 위해서 필요한 메모리 공간, 유저 영역 제외한 나머지

<aside>
❓ 프로세스가 종료되는 두 가지 조건에 대해 설명해주세요.

</aside>

- 프로세스의 마지막 명령이 실행을 마치는 경우
- 프로세스 종료 시스템 호출(예: exit())을 통하는 경우

⇒ 프로세스 종료 후 부모 프로세스에게 실행결과를 되돌려 줌

# 📔 CPU Scheduling

<aside>
❓ 자신이 알고 있는 CPU 스케줄링을 선점형, 비선점형으로 나누어 특징을 설명해주세요. 설명한 각 CPU 스케줄링의 단점을 설명해주세요.

</aside>

1️⃣ 비선점형 방식

- 하나의 프로세스가 CPU를 점유하고 있을 때에는 다른 프로세스가 현재 실행 중인 프로세스를 중단시킬 수 없다
- 비선점형 방식들은 모든 프로세스를 관리하는데 공정하다
- 일괄 처리 시스템에 적당
- 종류
    - FIFO
        - 먼저 들어온 것을 먼저 처리해준다
        - 처리방식이 공평하지만, 반환시간이 느리다
    - SJF
        - 짧은 작업을 우선적으로 처리
        - 무한 대기 상태 가능성
    - HRN
        - FIFO와 SJF의 단점을 보완한 방법
        - 실행 시간 추정과 선점 기능 때문에 스케줄러가 복잡해지고 남은 계산 시간들을 저장해 놓아야 하는 단점을 보완
        - 작업의 서비스받을 시간과 그 작업이 서비스를 기다린 시간으로 결정되는 우선순위에 따라 CPU를 할당

2️⃣ 선점형 방식

- 하나의 프로세스가 CPU를 점유하고 있을 때에는 다른 프로세스가 현재 사용 중인 프로세스를 중단시키고 CPU를 차지할 수 있는 방식
- 높은 우선순위의 프로세스들이 긴급을 요할 때 유용
- 빠른 응답 시간을 필요로 하는 대화식, 시분할, 실시간 처리에 적당
- 종류
    - RR
        - 동일한 시간 할당량을 사용하는 시분할 처리 시스템에 효과적으로 적용
        - 시간 할당량 안에 작업을 마치지 않으면 준비 대기 리스트의 가장 뒤로 배치되는 방식
        - 시간 할당량이 크면 비선점의 FIFO와 동일하며 시간 할당량이 작으면 문맥 교환수와 오버헤드가 증가
        - 적절한 응답 시간을 보장해주는 대화식 사용자에게 효과적
    - SRT
        - 작업이 끝나기까지 "남아 있는" 실행시간의 추정치가 가장 작은 프로세스를 먼저 실행하는 방식
        - 서비스받은 시간을 기록해야 하기 때문에 오버헤드가 증가한다
        - 특정 프로세스를 실행하고 있더라도, 빠른 프로세스 작업부터 처리
    - MFQ
        - 짧은 작업이나 입출력 위주의 작업에 우선순위를 부여하기 위해 개발된 방식
        - 큐마다 시간 할당량이 존재하며 낮은 큐일수록 시간 할당량은 커짐
        - 큐들은 종속적으로 연결되어 있으며 CPU를 시간 할당량만큼 사용한 프로세스는 낮은 큐로 이동
        - 마지막 큐는 RR를 사용

# 📔 Sync & Async

<aside>
❓ 동기와 비동기의 차이(블로킹, 넌블로킹) 를 장단점과 함께 설명해주세요.

</aside>

1️⃣ 동기와 비동기의 차이 → 호출되는 함수의 작업 완료 여부를 신경쓰는지의 여부

**동기**

- 장점 : 설계가 매우 간단하고 직관적
- 단점 : 결과가 주어질 때까지 아무것도 못하고 대기해야 함

**비동기**

- 장점 : 요청에 따른 결과가 반환되는 시간 동안 다른 작업을 수행 가능
- 단점 : 동기식보다 설계가 복잡

2️⃣ 블로킹과 넌블로킹의 차이 → A 함수가 B 함수를 호출했을 때, 제어권을 어떻게 처리하느냐

- 블로킹 : **블로킹**은 A 함수가 B 함수를 호출하면, **제어권을 A가 호출한 B 함수에 넘겨준다.**
    
    
    1. A함수가 B함수를 호출하면 B에게 제어권을 넘긴다.
    2. 제어권을 넘겨받은 B는 열심히 함수를 실행한다. A는 B에게 제어권을 넘겨주었기 때문에 함수 실행을 잠시 멈춘다.
    3. B함수는 실행이 끝나면 자신을 호출한 A에게 제어권을 돌려준다.
- 넌블로킹 : A함수가 B함수를 호출해도 **제어권은 그대로 자신이 가지고 있는다.**
    
    
    1. A함수가 B함수를 호출하면, B 함수는 실행되지만, **제어권은 A 함수가 그대로 가지고 있는다.**
    2. A함수는 계속 제어권을 가지고 있기 때문에 B함수를 호출한 이후에도 자신의 코드를 계속 실행한다.

3️⃣ 블로킹과 넌블로킹, 동기와 비동기

- **Sync-Blocking 동기-블로킹**
    
    
    함수 A는 함수 B의 리턴값을 필요로 한다(**동기**). 그래서 제어권을 함수 B에게 넘겨주고, 함수 B가 실행을 완료하여 리턴값과 제어권을 돌려줄때까지 기다린다(**블로킹**).
    
- **Sync-Nonblocking 동기-넌블로킹**
    
    
    A 함수는 B 함수를 호출한다. 이 때 **A 함수는 B 함수에게 제어권을 주지 않고**, 자신의 코드를 계속 실행한다(**논블로킹**).
    
    그런데 **A 함수는 B 함수의 리턴값이 필요하기 때문**에, 중간중간 B 함수에게 함수 실행을 완료했는지 물어본다(**동기**).
    
    ⇒ 논블로킹인 동시에 동기인 것이다.
    
- **Async-Nonblocking 비동기-넌블로킹**
    
    
    A 함수는 B 함수를 호출한다.
    
    이 때 제어권을 B 함수에 주지 않고, 자신이 계속 가지고 있는다(**논블로킹**). 따라서 B 함수를 호출한 이후에도 멈추지 않고 자신의 코드를 계속 실행한다.
    
    그리고 B 함수를 호출할 때 **콜백함수**를 함께 준다. B 함수는 자신의 작업이 끝나면 A 함수가 준 콜백 함수를 실행한다(**비동기**).
    
- **Async-blocking 비동기-블로킹**
    
    
    Async-blocking의 경우는 사실 잘 마주하기 쉽지 않다.
    
    A 함수는 B 함수의 리턴값에 신경쓰지 않고, 콜백함수를 보낸다(**비동기**).
    
    그런데, B 함수의 작업에 관심없음에도 불구하고, A 함수는 B 함수에게 제어권을 넘긴다(**블로킹**).
    
    따라서, A 함수는 자신과 관련 없는 B 함수의 작업이 끝날 때까지 기다려야 한다.
    
    Async-blocking의 경우 sync-blocking과 성능의 차이가 또이또이하기 때문에 사용하는 경우는 거의 없다.
    

<aside>
❓ 교착상태(데드락)란 무엇이며, 교착상태가 발생하는 조건을 설명해주세요.

</aside>

- 두 개 이상의 프로세스나 스레드가 서로 자원을 얻지 못해서 다음 처리를 하지 못하는 상태
- 무한히 다음 자원을 기다리게 되는 상태
- 시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생
    
    ⇒ 4가지 모두 성립해야 데드락 발생 (하나라도 성립하지 않으면 데드락 문제 해결 가능)
    
    1. `상호 배제(Mutual exclusion)`
        
        자원은 한번에 한 프로세스만 사용할 수 있음
        
    2. `점유 대기(Hold and wait)`
        
        최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야 함
        
    3. `비선점(No preemption)`
        
        다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없음
        
    4. `순환 대기(Circular wait)`
        
        프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함
        

<aside>
❓ 세마포어와 뮤텍스의 차이에 대해 설명해주세요.

</aside>

- 프로세스 간 메시지를 전송하거나, 공유메모리를 통해 공유된 자원에 여러 개의 프로세스가 동시에 접근하면 Critical Section(여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 블록) 문제가 발생할 수 있다.
- 이를 해결하기 위해 데이터를 한 번에 하나의 프로세스만 접근할 수 있도록 제한을 두는 동기화 방식을 취해야 한다.
- 동기화 도구 ⇒ 뮤텍스(Mutex)와 세마포어(Semaphore) 
⇒ 모두 공유된 자원의 데이터를 여러 스레드/프로세스가 접근하는 것을 막는 역할
- 차이점 : 동기화 대상 개수
    - Mutex는 동기화 대상이 오직 1개일 때 사용하며, Semaphore는 동기화 대상이 1개 이상일 때 사용합니다.
    - Mutex는 자원을 소유할 수 있고, 책임을 가지는 반면 Semaphore는 자원 소유가 불가합니다.
    - Mutex는 상태가 0, 1 뿐이므로 Lock을 가질 수 있고, 소유하고 있는 스레드만이 이 Mutex를 해제할 수 있습니다. 반면 Semaphore는 Semaphore를 소유하지 않는 스레드가 Semaphore를 해제할 수 있습니다.
    - Semaphore는 시스템 범위에 걸쳐 있고, 파일 시스템 상의 파일로 존재합니다. 반면, Mutex는 프로세스의 범위를 가지며 프로세스 종료될 때 자동으로 Clean up 됩니다.

# 📔 Memory Management

<aside>
❓ 운영체제의 메모리 관리 전략인 Contiguous Allocation, Noncontiguous Allocation의 차이점을 설명해주세요.

</aside>

- 연속 메모리 할당 (Contiguous)
    
    연속적인 메모리 공간을 프로세스에 할당하는 방식
    
    - 주소 변환으로 인한 CPU 오버헤드를 줄임 → 프로세스 수행 빠르게
    - **내부 단편화** 초래 가능성
    - 분류
        - 고정 파티션 할당 (Fixed Partition Allocation)
            
            메모리를 고정 크기의 파티션으로 나누고 각 파티션을 하나의 프로세스에만 할당하여 연속적인 메모리 할당을 달성
            
            → 동시 실행 프로세스 개수가 고정 티션 개수에 제한
            
        - 가변 파티션 할당 (Variable Partition Allocation)
            
            프로그램의 크기를 고려하여 프로세스에 할당할 파티션의 크기와 개수를 결정
            
- 비연속 메모리 할당 (Noncontiguous)
    
    여러개의 연속적이지 않은 메모리 공간을 프로세스에 할당하는 방식
    
    - 메모리 공간을 자유롭게 사용 가능 → **외부 단편화**로 인한 메모리 낭비 감소
    - 프로세스에 할당된 메모리가 연속적이지 않음 → 주소 변환으로 인한 CPU 오버헤드 증가 → 프로세스 수행시간 증가
    - 분류
        - 페이징 (Paging)
            
            프로세스의 가상 메모리를 동일한 크기의 페이지 단위로 나누어 물리적 메모리 공간에 불연속적으로 저장 → 내부 단편화 초래
            
        - 세그먼테이션 (Segmentation)
            
            프로세스의 가상 메모리를 논리적 단위인 세그먼트 단위로 나누어 물리적 메모리 공간에 저장 → 공유와 보안에 효과적 → 외부 단편화 초래
            
- 비교
    
    
    | Contiguous | Non Contiguous |
    | --- | --- |
    | 연속된 하나의 메모리 블록을 프로세스에 할당 | 여러 개의 연속적이지 않은 메모리 블록을 프로세스에 할당 |
    | 프로세스 실행 속도 빠름 | 프로세스 실행 속도 느림 |
    | OS 제어 쉬움 | OS 제어 어려움 |
    | 주소 변환이 줄어 CPU 오버헤드 감소 | 주소 변환이 많아져 CPU 오버헤드 증가 |
    | 주로 내부 조각화 | 주로 외부 조각화 |
    | 고정 파티션, 가변 파티션 | 페이징, 세그먼테이션 |

<aside>
❓ Swapping이란?

</aside>

주 기억 장치에 적재한 하나의 프로세스를 보조기억장치에 잠시 적재했다가 필요할 때 다시 꺼내서 사용하는 메모리를 교체하는 기법


- 프로세스가 현재 메모리에서 다른 저장공간 (HDD, SSD, ect.) 으로 옮겨졌다가 돌아왔다가 이런 식으로 실행에 따라 교체 됨
- 가상 메모리를 관리하는 과정에서 페이징 단위로 스와핑 진행
    
    → 메인 메모리보다 더 큰 메모리가 필요한 프로세스를 실행할 때 도화주는 역할을 하기 때문
    

<aside>
❓ Swapping 시 발생할 수 있는 문제점?

</aside>

문맥 교환 시간이(오버헤드) 상당히 오래 걸림 

<aside>
❓ 외부 단편화를 해소할 수 있는 방법 두 가지 제시

</aside>

1️⃣ 메모리 압축

연속 메모리 할당을 계속 진행하면서 발생한 짜투리 메모리들을 하나로 합쳐 큰 메모리 공간을 만드는 것

- 쉽게 이룰 수 있는 것이 아니며 압축을 하려면 현재 할당되어 있는 프로세스들의 메모리 위치를 옮겨줘야만 한다
- 한 작업이 운영체제에서는 꽤 시간이 필요한 작업이기 때문에 이것을 프로세스가 실행되는 중간중간에 동적으로 진행하는것은 효율적이지 않다

2️⃣ 페이징과 세그멘테이션

한 프로세스의 논리 주소 공간을 여러 개로 분할하여 비연속적인 물리 메모리 공간에 할당

- 메모리 압축보다 조금 더 효율적인 방법

# 📔 Paging & Segmentation

<aside>
❓ 페이징과 세그먼테이션에 대해서 설명하세요.

</aside>

- 페이징 (Paging)
    
    프로세스의 가상 메모리를 동일한 크기의 페이지 단위로 나누어 물리적 메모리 공간에 불연속적으로 저장
    
    - **장점**
        
        논리 메모리는 물리 메모리에 저장될 때 연속되어 저장될 필요가 없고, 물리 메모리의 남는 프레임에 적절히 배치되기 때문에 외부 단편화가 생기지 않음
        
    - **단점**
        
        내부 단편화 문제가 발생 가능성,  페이지 매핑 과정이 복잡해져 오히려 비효율적
        
- 세그먼테이션 (Segmentation)
    
    프로세스의 가상 메모리를 논리적 단위인 세그먼트 단위로 나누어 물리적 메모리 공간에 저장 → 공유와 보안에 효과적
    
    - **장점**
        
        내부 단편화 문제가 해소
        
        보호와 공유 기능을 수행 가능
        프로그램의 중요한 부분과 중요하지 않은 부분을 분리하여 저장 가능하며 같은 코드 영역은 한 번에 저장할 수 있음
        
    - **단점**
        
        외부 단편화 문제
        

<aside>
❓ 내부 단편화와 외부 단편화가 무엇인지 설명하세요.

</aside>

- 단편화
    
    RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용가능한 메모리가 충분히 존재하지만 할당(사용)이 불가능한 상태
    
- 내부 단편화
    
    
    메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비 되는 현상
    
- 외부 단편화
    
    
    메모리가 할당 및 해제 작업의 반복으로 작은 메모리가 중간중간에 존재 중간중간에 생긴 사용하지 않는 메모리가 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황
    

# 📔 Vertual Memory

<aside>
❓ 가상 메모리가 필요한 이유를 하는 일과 관련지어 설명해주세요.

</aside>

램과 하드디스크를 하나의 추상화된 메모리 영역으로 제공

- 프로세스가 운영체제(시스템) 전체에 문제가 나는것을 막기 위해
- 프로세스의가 사용하는 공간을 가상세계로 범위를 제한시켜 애플리케이션이 죽어도 OS는 살아남는다. (시스템 안정성을 위해)
- OS가 프로그램에게 가상메모리 영역을 할당하기 때문에 프로그램이 뻗어도 OS가 해당 프로그램의 주소위치를 알기 때문에 자원을 회수할 수 있어 메모리의 낭비가 없고, 프로그램이 죽어도 OS에 영향이 없다.

<aside>
❓ 요구 페이징이란 무엇이고, 요구 페이징에서 Page Fault가 발생했을 때, 처리되는 Page 교체 순서에 대해 설명해주세요.

</aside>

1️⃣ 요구 페이징

- 필요한 부분만 물리적 메모리에 page단위로 적재하는 방법
- 특정 page에 대해 cpu요청이 들어온 후에 해당 page를 메모리에 적재
- 당장 필요한 page만을 메모리에 적재하기 때문에 메모리 사용량이 감소
- 프로세스 전체를 메모링 적재하는 입출력 오버헤드도 감소
- 유효/무효 비트(valid/invalid bit)를 ****두어 각 page가 메모리에 존재하는지 표시
- 유효/무효 비트 : 해당 비트가 유효하면 메모리에 있음을 의미, 무효하면 메모리에 없음을 의미
- CPU가 무효비트로 표시된 page에 엑세스하는 상황

2️⃣ Page 교체 알고리즘 (replacement algorithm)

- page fault가 발생하면, 요쳥된 page를 디스크에서 메모리로 가져옴
    - 물리적 메모리 공간이 부족한 상황이 발생할 수 있음
- 메모리에 올라와 있는 page를 디스크로 옮겨서 메모리 공간을 확보
- 이를 페이지 교체라고 하고, 어떤 page를 교체할지 결정하는 방법은 Page 교체 알고리즘에 따라 달라짐
- 이 교체 알고리즘은 최대한 page fault가 적게 일어나도록 도와줌
- 앞으로 사용될 일이 적은 page를 선택하여 교체하는 것이 성능 향상

# 📔 Page replacement

<aside>
❓ 페이지 부재(page fault)가 무엇인지 설명해주세요.

</aside>

페이지 부재를 처리하는 과정

- CPU가 특정 페이지를 접근하여 페이지 테이블에서 무효 상태인지 아닌지 확인
- 페이지가 무효 상태일 경우 MMU에서 Page fault trap이 발생
    - MMU : 가상 주소를 물리 메모리 주소로 변환해주는 하드웨어 장치
- 디스크에서 해당 페이지를 빈 프레임에 적재하고 페이지 테이블을 업데이트 (무효 -> 유효)
- 트랩에 의해 중단되었던 명령을 다시 수행

<aside>
❓ 페이지 교체란 무엇인지 설명해주세요.

</aside>

Vertual Memory 두번째 질문 참고

<aside>
❓ 페이지 교체 알고리즘의 종류와 각각의 특징에 대해 설명해주세요.

</aside>

| 알고리즘 | 설명 |
| --- | --- |
| OPT(Optimal) | 앞으로 가장 오랫동안 사용하지 않을 page를 찾아 교체
(실제로 구현하기 거의 불가능) |
| FIFO(First in First Out) | 메모리에 올라온지 가장 오래된 page를 교체 |
| LRU(Least Recently Used) | 가장 오랫동안 사용하지 않은 page를 교체 |
| LFU(Least Frequently Used) | 가장 참조횟수가 적은 page를 교체 |
